
# Telco Customer Churn - ML Project

## Objective
This project builds a **binary classification model** to predict whether a telecom customer will **churn** (`Churn=Yes`), using the Telco Customer Churn dataset.

Primary objective (per rubric + competition constraint):
- **Maximize Recall for Churn = 1** (catch as many churners as possible)
- While enforcing the constraint **F1 $\scriptsize\ge$ 0.50**
- Using a **leakage-safe** ML workflow (all preprocessing/SMOTE/selection fit only within training folds)

---

### What each folder contains
- **`data/raw/`**  
  Original dataset input (do not edit this file).
- **`data/processed/`**  
  Cleaned/processed datasets generated by the notebook (e.g., numeric-fixed `TotalCharges`).
- **`figures/`**  
  All plots generated by the notebook (every plot is saved here with consistent filenames).
- **`models/`**  
  Saved model artifacts (pipelines and trained estimators via joblib/pickle).
- **`project.ipynb`**  
  The full rubric-ordered notebook (runs top-to-bottom from a fresh kernel).
- **`final_report.md`**  
  Final written report summarizing EDA, modeling, results, and recommendations.

---

## Data
- Input file (required):  
  `./data/raw/telco-customer-churn-dataset.csv`

Expected columns (original order preserved when displaying schema):
`customerID, gender, SeniorCitizen, Partner, Dependents, tenure, PhoneService, MultipleLines, InternetService,
OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, Contract,
PaperlessBilling, PaymentMethod, MonthlyCharges, TotalCharges, Churn`

Important notes:
- `customerID` is **never** used as a predictive feature.
- `TotalCharges` is often read as a string; the notebook converts it to numeric and handles blank-string missingness.

---

## How the notebook works (high-level)
The notebook follows these phases:

1. **EDA**
   - Data understanding: shape/types/duplicates
   - Univariate: numeric histograms + categorical bars
   - Bivariate: correlations + churn-rate comparisons by key features

2. **Preprocessing (leakage-safe)**
   - Fix `TotalCharges` type + missing values
   - `ColumnTransformer`:
     - numeric $\scriptsize\rightarrow$ impute + scale
     - binary $\scriptsize\rightarrow$ ordinal encode
     - categorical $\scriptsize\rightarrow$ one-hot encode
   - All transforms are fit only on training folds inside pipelines.

3. **Feature engineering**
   - Creates $\scriptsize\ge$ 2 new meaningful features (e.g., charges intensity, service bundle counts).

4. **Feature selection**
   - Filter + model-based: Chi2 / L1 LogisticRegressionCV / RandomForest importances
   - Uses an explicit selection rule and includes stability evidence across folds.

5. **Modeling & optimization**
   - Multiple model families (LR, SVM, RF, XGBoost)
   - Handles imbalance via SMOTE inside `imblearn.Pipeline`
   - Hyperparameter tuning for $\scriptsize\ge$ 2 models
   - Soft-voting ensemble

6. **Final evaluation & threshold selection**
   - Reports metrics table (Accuracy/Precision/Recall/F1)
   - ROC-AUC comparison for top models
   - Threshold tuning using **OOF probabilities** on train only:
     - choose threshold to maximize Recall subject to **F1 $\scriptsize\ge$ 0.50**
   - Final evaluation on test set **once** using the selected threshold
